---
title: "KNN_tidymoodels"
author: "liuc"
date: '2022-05-26'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## KNN

> https://mp.weixin.qq.com/s/Qqal3Afl8AoY_yxT8V8VOw


依旧使用隔壁prostat的数据集，可以看出大部分`tidymodels`的操作逻辑和`scikit-learn`一样具有模式化，这也是其的主要目的，虽然具体模型在matric等方面不同，不过大部分还是一致的，建模、模型评估、在测试集的评估参数等总是需要的。

k-近邻算法（k-Nearest Neighbour algorithm）的工作原理：给定一个已知标签类别的训练数据集， 输入没有标签的新数据后，在训练数据集中找到与新数据最邻近的 k 个实例，如果这k 个实例的多数属于某个类别， 那么新数据就属于这个类别。即由那些离新数据最近的 k 个实例来投票决定新数据归为哪一类。

1. 计算已知类别数据集中的点与当前点之间的距离；
2. 按照距离递增次序排序；
3. 选取与当前点距离最小的 k 个点；
4. 确定前 k 个点所在类别的出现频率；
5. 返回前 k 个点出现频率最高的类别作为当前点的预测类别。


从其的定义中似乎可以看到模型中包含训练数据集？还有两个需要注意的点，最近邻是如何定义计算的？K值如何确定？如果K值等于训练集中所有点，那么模型就极端的简化为只有一种结果了，不论输入什么数据，其的分类都是训练集中点最多的那个分类。定义中所说的最近邻又是如何度量的呢？几种常见的距离度量的方法：欧式距离、Minkowski距离、曼哈顿距离。

kd树的结构.


*knn中数据的输入和处理：*特征归一化的必要性。归一化的目的在于让每一个变量具有同等的重要性，不过还是赋予权重更合理。


*knn的超参数：*neighbors(K的数目)，weight_func(), dist_power(在kknn包中似乎只提供了Minkowski distance)


#### 1. 加载需要的包
```{r}
library(tidyverse)
library(tidymodels)
library(usemodels)
```


#### 2. 整理输入数据并考虑好变量所要进行的操作

```{r}
# 参考SVM数据集

usemodels::use_kknn(formula = class ~ ., data = prostat_train)
```



#### 3. CV+GS 得到一系列表现的模型

一个72个样本、9300个变量的数据集，竟然跑了如此之久！Don't run it on your Mac!!!在服务器10个进程大概40分钟。

```{r}
kknn_recipe <- 
  recipe(formula = class ~ ., data = prostat_train) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) 

kknn_spec <- 
  nearest_neighbor(neighbors = tune(), weight_func = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kknn") 

kknn_workflow <- 
  workflow() %>% 
  add_recipe(kknn_recipe) %>% 
  add_model(kknn_spec) 


doParallel::registerDoParallel()
prostat_folds <- vfold_cv(prostat_train, strata = class)
metrics = metric_set(accuracy, roc_auc, sens, spec)


```

```{r, eval=FALSE}
# 已经运行结束，直接load
set.seed(42)
kknn_tune <-
  tune_grid(kknn_workflow, 
            resamples = prostat_folds, 
            grid = 20 # 生成20个网格搜索的结果
            )
kknn_tune
```

在tune完多个模型参数后，统一的查看其的metrics以进一步确定所需要的模型参数。
```{r}
kknn_tune <- readRDS('./datasets/kknn_tune.rds')

kknn_tune %>% 
  collect_metrics()
```


*choose the best model*
依据roc-auc选择表现最佳的模型
```{r}
show_best(kknn_tune)

best_auc <- select_best(kknn_tune, "roc_auc")

final_mod <- finalize_model(
  kknn_spec,
  best_auc
)

final_mod
```


然后用得到的最佳参数重新拟合模型.
```{r}
final_wf <- workflow() %>% add_model(final_mod) %>% 
  add_formula(class ~ .)
# 此处的fit是否需要呢, final_res$.workflow[[1]]应该就是在训练集上的最后的模型
final_fit <- final_wf %>% fit(prostat_train)


```

```{r}
# last_fit在训练集拟合，在测试集verify performance
final_res <- final_wf %>%
  last_fit(split = df_split)
final_res %>% 
  collect_metrics()
```



模型评价参数：
包括混淆矩阵和灵敏度、特异性等指标，不仅在测试集数据上需要，在训练集数据上也需要进行展示
```{r}
# confusion matrix
final_res %>%
    collect_predictions() %>%
    conf_mat(class, .pred_class)

# auc-roc
final_res %>%
  collect_predictions() %>%
  roc_curve(class, .pred_0)

final_res %>%
  collect_predictions() %>%
  roc_auc(class, .pred_0)

```


验证是否一致, final_fit & final_res$.workflow[[1]]是否是同一个对象。
初步验证是一样的。
```{r}
cancer_pred <- predict(final_fit, new_data = prostat_test) %>%
  bind_cols(predict(final_fit, prostat_test, type = "prob")) %>%
  bind_cols(prostat_test %>% select(class))

cancer_pred2 <- predict(final_res$.workflow[[1]], new_data = prostat_test) %>%
  bind_cols(predict(final_res$.workflow[[1]], prostat_test, type = "prob")) %>%
  bind_cols(prostat_test %>% select(class))

cancer_pred
cancer_pred2
```


保存模型：
```{r}

```








