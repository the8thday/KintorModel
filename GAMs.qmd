---
title: "General Additive Models"
format: html
---

### General Additive Models

主要参考以下资料：

> https://m-clark.github.io/generalized-additive-models/preface.html
> https://noamross.github.io/gams-in-r-course/chapter1

<\br>

General/Generalized Additive Models (GAMs) are a powerful class of models that extend the capabilities of traditional GLMs. In particular, they are able to parsimoniously model possibly non-linear relationship.

一般加性模型和广义加性模型一般用于model 非线性的关系。其自然也是可以model线性关系的，比如对变量间关系不确定时支持使用
广义加性模型也是可以的。

从对不符合线性关系的Y和x的描述中，有些数据拟合对predictor进行transform也不易做到，诸如splines，cubic等。Transformation often exacerbate data issues or fail to help. 

GAMs对其的predictors应用一些smooth function(like splines):

$g(ui)=A_{i} + f_{1}(x_{1}) + f_{2}(x_{2i}) + ...$


`mgcv`的`s()`, `lo()` 等smoother:
<!-- ?smooth.terms -->
- `s()` 平滑器指定为样条平滑
- `lo()` 指定为LOESS平滑
- `te()` tensor product smooth


在广义线性模型的计算中，g() 和 link()都是对于respose变量而言的。link function maps a nonlinear relationship to a linear one so that a linear model can be fit (and then mapped to the original form).


```{r}
library(tidyverse)
library(easystats) # every model need it !
library(mgcv) # 首选R包
# library(gam)
library(gratia)
# library(GAMLSS)
library(scam)
```



### 用mgcv model一个线性关系

GAM 模型亦可用于一般线性模型之中

```{r}
# Generate data
data <- bayestestR::simulate_correlation(r = 0.85, n = 1000, names = c("y", "x"), 
                                         mean = c(100, 0), sd = c(15, 1))

# we need to specify a smooth term (s()) for the variable for which we want to estimate the (non-necessarily linear) relationship.
model_gam <- mgcv::gam(y ~ s(x), data = data)

plot(modelbased::estimate_relation(model_gam), line = list(color = "blue"))
```


```{r}
parameters::parameters(model_gam)
```

Check your model:

```{r}
mgcv::gam.check(model_gam)
```


#### 用lm model 线性模型

可以看到lm和gam的结果极为类似。

`estimate_relation`的结果几乎一致。

```{r}
model_lm <- lm(y ~ x, data = data)

plot(modelbased::estimate_relation(model_lm))

parameters::parameters(model_lm)
```


#### effect derivative

在前面的两个模型示例中，lm model给出了x变量的slope，也即x每改变一个单位y所改变的值。然而gam model确无法给出这样的一个
coefficient。其实有一个更为通用的方法，即效应求导可以帮组得到对应的系数值。

而且其可以用于任何模型。方便于interpret GAM模型的结果。

*求导是个好东西*

```{r}
deriv <- modelbased::estimate_slopes(model_gam, trend = "x", at = "x")

plot(deriv, line = list(color = "blue")) +
  geom_hline(yintercept = 0, linetype = "dashed")

# 可以看到coefficient的结果和lm model的结果很是类似
summary(deriv)
```
上述结果可以看到coefficient的结果和lm model的结果很是类似.


#### GAM 用于多项式线性模型的对比


```{r}
dd = readr::read_csv('datasets/pisasci2006.csv')

p <- GGally::ggpairs(dd %>% select(-Country))

plotly::ggplotly(p)
```



```{r}
summary(mgcv::gam(Overall ~ Income, data = dd))

summary(stats::lm(Overall ~ Income, data = dd))
```


```{r}
# ?s
# ?summary.gam

mod_gam1 = mgcv::gam(Overall ~ s(Income, bs = "cr"), data = dd)
summary(mod_gam1)
```

结果阐释：`edf( effective degrees of freedom)` : due to the smoothing process and the penalized regression estimation procedure, GAM's degree of freedom 不在是直接的特征数量。 The edf with value 1 suggests that it has essentially been reduced to a simple linear effect. 

`GCV(generalized cross validation)`score  can be taken as an estimate of the mean square prediction error based on a leave-one-out cross validation estimation process.  lower being better.

GAM的一些特征和一些机器学习的建模方法倒是挺像的。

*可以看到mod_gam1 比lm的结果好*




### 一个完备切实可行的GAM建模分析过程

在拿到数据和对应的实验设计之后，首要的是确定数据适合用什么样子的模型。

对于`mgcv`包，记得分类变量变成factor。一般的，分类变量在gam模型中以linear处理。
`model4b <- gam(hw.mpg ~ s(weight, by = fuel) + fuel, data = mpg,method = "REML")`

```{r}
# 一些测试数据
library(gamair)
data("mpg", package="gamair")

dd <- readr::read_csv('./datasets/pisasci2006.csv')


set.seed(0)
dat <- mgcv::gamSim(1,n=600, scale=0.6, verbose=FALSE)
```

散点图查看数据的分布:

一些变量的分布呈现曲线分布的情况。

如何在设定一个target(outcome)的情况下查看数据的探索呢，dlookr似乎是可以的。

```{r}
GGally::ggpairs(dd %>% select(-Country))
```

利用`dlookr`包进行数据探索：
```{r}
require(dlookr)

categ <- target_by(dd, Overall)

dlookr::eda_report(categ)
```



```{r}
# sp(smoothing parameter) 即可以放在s()中，也可以放在gam()中
# k 参数, number of basis functions
# In practice, we rarely make continuous variables linear in GAMs. This is because, if the relationship is really linear, or there is not enough data to show otherwise, automatic smoothing will force a linear shape.

# mod_gam <- gam(Overall ~ s(Income) + s(Edu) + s(Health), data = dd, 
#                 method = "REML")

mod_gam <- gam()

summary(mod_gam)
mod_gam$sp

# extracts the coefficients of these basis functions the GAM model object.
# The coef() function extracts all the model coefficients, which are coefficients for each basis function that makes up the smooth.
# coef(mod_gam2)

mod_gam2B <- update(mod_gam, . ~ . - s(Health) + Health)
```
*interpret results: *The "Family" component tells us the model assumes a Gaussian or normal distribution of our errors, and the "Link" of "identity" shows that the model doesn't transform the predictions.
Parametric means models that have a pre-determined form. In this context, it refers to the linear terms in the model.
For smooths coefficients are not printed. This is because each smooth has several coefficients - one for each basis function. Instead, the first column reads edf, which stands for effective degrees of freedom. This value represents the complexity of the smooth. An edf of 1 is equivalent to a straight line. An edf of 2 is equivalent to a quadratic curve, and so on, with higher edfs describing more wiggly curves.

A good way to interpret significance for smooth terms in GAMs is this: a significant smooth term is one where you can not draw a horizontal line through the 95% confidence interval.



__模型诊断：__如果gam.check结果偏离较高，可以通过调整basis function数目等进行调整。p-value小于0.05一般认为需要在 增加k的数目。

```{r}
# partial effect plots
# they show the component effect of each of the smooth or linear terms in the model, which add up to the overall prediction.
# by default we only see the smooth plots, but by setting all.terms = TRUE, we can display partial effects of linear or categorical terms, as well.
plot(mod_gam, page = 1, all.terms = TRUE, residuals = TRUE, shade = TRUE,
     shade.col = "lightblue"
     )

# p-value 小于0.05indicate that residuals are not randomly distributed. This often means there are not enough basis functions.
# 四幅图都是对残差的绘图,第三幅最好在0附近
gam.check(mod_gam, k.rep = 1000)


# 弯曲度
# 三个值各有其用处，比如worst大于0.8可就要小心了
concurvity(mod_gam)
# pairwise
concurvity(mod_gam, full = FALSE)
```

`gratia`包提供的一些功能很方便进行美化：

```{r}
gratia::draw(mod_gam, residuals = TRUE)

gratia::appraise(mod_gam)
```


`easystats`包的一些应用

```{r}
# check_model(mod_gam) # not supported yet!

parameters(mod_gam) # 同summary
```





### Logistic GAMs for Classification


Logistic and Logit Functions in R:

GAM所返回的结果是log-odds的结果，需要通过plogis()转换成probability.

```{r}
plogis() # Logistic
qlogis() # Logit

qlogis(plogis(0.5))

qlogis(0.25) == log(1/3) # ....
```


```{r}
csale <- readRDS('./datasets/csale.rds')

log_mod <- gam(purchase ~ s(n_acts) + s(bal_crdt_ratio) + s(mortgage_age) + s(avg_fin_balance) + s(retail_crdt_ratio) + s(cred_limit) + s(avg_prem_balance),
                data = csale,
                family = binomial,
                method = "REML")
```

The output of a logistic GAM looks similar to that of previous GAMs we fit.However, it's important to understand that outputs are on the log-odds scale. To interpret them as probabilities, we need to convert them using the logistic function.We can use the plogis() logistic function to convert it to a probability. 转换后的interept值表示在其他变量取均值时， 二分类结局具体发生的概率。


```{r}
# 直接plot，是plot的log-odds，不易于解释
# transformed from log-odds to probabilities
plot(log_mod, pages = 1, trans = plogis)

# Adding an intercept
plot(log_mod, pages = 1, trans = plogis,
     shift = coef(binom_mod)[1])

plot(log_mod, pages = 1, trans = plogis, shift = coef(log_mod)[1],
     seWithMean = TRUE, rug = FALSE, shade = TRUE, shade.col = "lightgreen", 
     col = "purple")
```

plot的结果，可以确定对outcome作用最大的自变量(y抽的大小)，每一个变量的图，都是在其他变量取average时得到的。


```{r}
gam.check(log_mod)
```



*making prediction*
```{r}
# type 的 link 和 response的差别在于前者返回log-odds scale，后者返回probability
predict(log_mod, type = "link")
predict(log_mod, type="response")

# If you use standard errors to construct confidence intervals for your predictions, you should do so on the log-odds scale, and then convert them to probability using the plogis() logistic function.
plogis(predict(log_mod, type="link", se.fit = TRUE))
```

```{r}
# Calculate high and low predictions intervals
predictions <- predict(log_mod, type = "link")
high_pred <- predictions$fit + 2*predictions$se.fit
low_pred <- predictions$fit - 2*predictions$se.fit
```





### bayesian interpret in GAMs

```{r}

```

