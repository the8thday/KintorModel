---
title: "linear mixed effect model"
author: "liuc"
date: "10/28/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## linear mixed effect model

> https://m-clark.github.io/mixed-models-with-R/random_intercepts.html
> https://poissonisfish.com/2017/12/11/linear-mixed-effect-models-in-r/
> https://bbolker.github.io/mixedmodels-misc/
> https://journals.sagepub.com/doi/full/10.1177/2515245920960351
> https://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet/13173#13173
> https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4
> https://stats.stackexchange.com/questions/58745/using-lmer-for-repeated-measures-linear-mixed-effect-model?rq=1
> https://stats.stackexchange.com/questions/65371/mixed-model-with-1-observation-per-level
> https://stats.stackexchange.com/questions/488428/how-do-you-know-the-number-of-random-effects-in-a-mixed-effects-model
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
> https://drive.google.com/file/d/1sOZUAFOc004H4jO8vuUc_4HyYHEgu45b/view


对于医学中常见的纵向数据，同一个受试者在不同时间的因变量值是相关的，不同受试者的因变量值可以认为不独立。线性混合模型用来解释因变量的连续型和分类型自变量的作用称为*固定效应*， 个体之间的差别的影响称为*随机效应*,随机效应是用来代表观察对象间的差异以及观察对象内的差异（如由重复测量造成的相关性），这些差异是随机的且不可观察到的。

mixed effects model average trends, random effects model the extent to which these trends vary across levels of some grouping factor.混合效应模型可以量化不同群体间平均趋势的差异程度。这里的grouping factor指的是对数据进行分组的因素, 比如地区、性别等。

混合模型的优点之一就是可以处理不等距时间数据，这对于分析临床回顾性研究中收集的患者不等距时间点上的重复测量数据是非常合适的。


*线性混合效应模型原理：*
假设随机效应满足正态分布(似乎有带商榷),即每个群体的随机效应都是从总体随机效应的正态分布中独立取样的。在线性混合效应模型 (LMM) 中，因变量被视为固定效应和随机效应的线性组合。


线性混合模型的应用较多，此处只针对医学研究中常见的重复测量数据分析。

*一个需要注意点在于怎么引入交互作用：*下面这段摘抄是一个不错的建议，For the so called ‘fixed effects’, one typically specifies effects of time (as a categorical or factor variable), randomised treatment group, and their interaction. This implies a saturated model for the mean, or put another way, there is a separate mean parameter for each time point in each treatment group. Often there are baseline covariates to be adjusted for. One can adjust for these as simple main effects, or additionally with an interaction with time, in order to allow for the association between the baseline variable(s) and outcome to potential vary over time. For a more in depth discussion of the model, see for example Molenberghs et al 2004 (open access). 一般来说需要考虑时间和group的交互，以及时间和base line间的交互。随机项的话，或者一个随机截距，或者随机time系数。过多的需要考虑的分组信息是一个需要小心的事情。
`m2 <- lmer(Obs ~ Treatment * Day + (1+Day|Subject), mydata)`

Essentially, an MMRM is a specific linear mixed effects model that includes (at least) an interaction of treatment arm and categorical visit variables as fixed effects. The covariance structure of the residuals can have different forms, and often an unstructured (i.e. saturated parametrization) covariance matrix is preferred. This structure can be represented by random effects in the mixed model. 


```{r, include=FALSE}
library(tidyverse)
library(easystats)
library(lme4)
library(lmerTest)
library(ggeffects)
library(emmeans)
library(mmrm) # 一个针对临床重复资料设计的R包

# data(package = 'lme4')
```

## use lmer

> https://ase.tufts.edu/bugs/guide/assets/mixed_model_guide.html

首先是检验数据因变量的概率分布，在这一点上似乎和一般线性模型相似，线性混合模型需要因变量满足正态性（目前来看值得商榷）.线性混合模型的统计推断如t检验、F检验依赖于残差的正态性和方差的齐性,而不是依赖于因变量的正态性。
如果不符合正态性检验，需选择正确的建模方法，比如penalized quasilikelihood (PQL) 、Laplace approximation and Markov chain Monte Carlo algorithms (MCMC).

PQL is a flexible technique that can deal with non-normal data, unbalanced design, and crossed random effects. However, it produces biased estimates if your response variable fits a discrete count distribution, like Poisson or binomial, and the mean is less than 5 - or if your response variable is binary.`MASS::glmmPQL`

The Laplace approximation can handle up to 3 random effects.Any more than that, and you'll have to use MCMC, which is a Bayesian method that can be somewhat confusing.

the Laplace approximation is a special case of a parameter estimation method called Gauss-Hermite quadrature (GHQ), with one iteration. GHQ is more accurate than Laplace due to repeated iterations, but becomes less flexible after the first iteration, so you can only use it for one random effect. 

不过通过performance::check_models似乎更安全 ，不确定此处的正态性检验是对因变量还是残差。   

除此之外，*对于outlier等数据的处理、NA值的处理*等，此处所使用的数据暂不考虑这些，只是主要结果的笔记。


*总结一下，线性混合效应模型的假设assumption：*

1. 解释变量和相应变量间线性相关
2. 残差独立、正态分布、并have constant variance
3. Normally distributed random effects - The random effects are usually assumed to be normally distributed.
4. No extreme multicollinearity ;No extreme outliers


```{r}
df2 <- readRDS('./datasets/df2.rds')

car::qqPlot(df2$score)
car::qqp(log(df2$score))
car::qqp(df2$score, 'lnorm')
# 可以看到数据不是很符合正态分布，但符合正态分布在实际中不是一件简单的事情，差不多就可以。
# 像本次数据的分布有些过于不符合了
```

寻找最佳随机效应结构,找到了模型最好的随机效应结构，接下来我们就给模型加入固定效应。
lme模型的构建在先验知识外，可以展开随机效应结构的筛选。
但怎么判定一个变量是固定效应变量还是随机效应变量呢？有人讲尝试每一个变量作为随机效应，但似乎并不可取。通过对项目本身的知识来选择似乎更靠谱。

REML estimation is unbiased but does not allow for comparing models with different fixed structures. Only use the REML estimation on the optimal model.

所以在进行效应选择的时候，用ML算法。

*随机效应的选择*
```{r}

nullmodel1 <- lme4::lmer(score ~ 1 + (1|PatientID), data = df2, REML=FALSE)
nullmodel2 <- lme4::lmer(score ~ 1 + (1 + class |PatientID), data = df2, REML=FALSE)

# 一个常见的报错，即随机效应的数目大于等于观察数目
# 比如以下这个公式，其time|PatientID的数目和观察的数目相等，即是考虑了随机截距和随机slope后，随机效应的
# 数目为231, 不过这个问题很神奇，因为同一患者在不同时间点测多次，必然是和观察数目相等的。
# sleepstudy这个测试数据集却是没有问题的，不过如果将Days变成factor，同样的问题依旧会出现
# lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy) 没有任何问题, str(sleepstudy)
# 目前来看应该就是样本数目不够的缘故
# 随机效应的数目计算为77+77？，这里应该考虑不同的分类因子变量来计算不同的随机效应的数目,所以是3*77，也就是刚才提到的，不论怎样，观察和随机效应值都会是一样的，报错总会有！！
# time |PatientID的写法中，除了会计算其他的效应，还会计算time在每一个PatientID的效应。
# The | symbol indicates a grouping factor in mixed methods.
# 所以在time combine PatientID时，只有一个观察值的情况下，这种纳入是不正确的。不要纳入time的随机slope。
nullmodel3 <- lme4::lmer(score ~ 1 + (1 + time |PatientID), data = df2, REML=FALSE,
                         control=lmerControl(check.nobs.vs.nRE="ignore") # wouldn't recommend it.
                         )

# 以下没有任何问题
nlme_m <- nlme::lme(score ~ time, random = ~ 1 + time | PatientID, 
               method = "REML", data = df2)
intervals(nlme_m)
# 有问题
nlme_m2 <- nlme::gls(
  score ~ time,
  # Specify a general correlation structure
  correlation = corSymm(form = ~ time | PatientID),
  # Specify constant variance for all Days
  # weights = varIdent(form = ~1),

  # Or let the variance vary by Day
  # weights = varIdent(form = ~ 1 | time),
  data = df2
)

summary(nlme_m)

anova (nullmodel1, nullmodel2) #  基于LRT比的模型间的对比，同时还考虑模型的AIC/BIC/
```

*报错问题的解决：*首先是考虑随机效应的数目，随机效应数目的计算方式为，1|PatientID，其随机效应值为77，time | PatientID, 因为time是一个分类变量，则其在计算时time*77便是随机效应值，在这个意义上来讲，数据在time上不是repeated measures，不能将time视为随机效应。
This is because the levels of a categorical variable are represented by dummy variables - essentially they are treated as different variables. So in your case, when you fit random slopes only you are asking the software to estimate 5 random slopes for each group. When you fit random intercepts and random slopes there will be 407 random intercepts, but only 4 random slopes for each group (since one level will be treated as a reference group and included in the intercept), so either way you will have 5 x 407 random effects.

The only way to solve this is by either coding the variable as `numeric`, if that is plausible in your study/data, or not fitting random slopes, or having more than 1 observation per treatment per group.


```{r}
test_performance(nullmodel1, nullmodel2)

compare_performance(nullmodel1, nullmodel2) |> plot()
```


上面的结果可以看到，nullmodel1有较好的指标，所以只选择随机intersect即可，不用考虑其他变量的随机slope。

固定效应的纳入，一般结合具体问题和样本量进行取舍。变量的纳入参考10人1️变量。

```{r}
# https://rpubs.com/rslbliss/r_mlm_ws#:~:text=To%20run%20a%20multilevel%20linear,we%20have%20used%20thus%20far.&text=Note%20that%20R%20uses%20restricted%20maximum%20likelihood%20to%20fit%20the%20model.
# same df2 data as in gee.Rmd

# 以入组后的2次测量值为因变量， 以处理效应、时间效应等为固定效应， 以不同病人作为随机效
lme_model <- 
  lmerTest::lmer(score ~ time + class + AGE + (1 | PatientID),
             data = df2
             )
summary(lme_model)

lme_model2 <- 
  lme4::lmer(score ~ time * class + AGE + (0 + class |`PatientID`),
             data = df2
             )

lme_model3 <- update(lme_model2, .~.-AGE)
# To keep the intercept fixed while keeping the random slope, replace the “1” with a “0”
```

*结果解读：*everything to the left of the | indicates the effects that should be random, and the variable to the right of the | is the grouping variable across which the effects should vary. What is the “1”? It’s the way we refer to the intercept.
lme模型和gee.Rmd中的示例为同一数据，我们在只考虑随机截距的情况下，Fixed effects中Estimate值和gee结果保持一致，说明自变量。random effects为随机效应， Groups列为随机效应因素, 此处只对Intercept的PatientID考虑了随机因素, 通过其Variance的大小可以判断随机截距效应是否应该考虑.
*REML criterion at convergence: *REML(restricted maximum likelihood), 
*Random effects: * The “Residual” standard deviation refers to σ. 如果Variance太小的话，则随机效应可能不太重要。
*Fixed Effects: * 随机效应的解释可以为timeDay1对比于(Intercept)中的timeDay0，score值减少了-147.260。AGE变量的话是可以不用考虑的。


```{r}
sjPlot::tab_model(lme_model,
                  p.val = "kr", # kr 方法计算的p值更为精准
                  show.df = TRUE
                  )

gtsummary::tbl_regression(lme_model,
                          intercept = TRUE
                          )
```


```{r}
lme4::VarCorr(lme_model)

# 可重复性
# 如果你得到的重复性小于1.0，那么个体内测量结果之间的变化来源是什么。仅是测量误差吗？
216.0^2/(216.0^2 + 417.9^2)
```


Estimates of Covariance Parameters:
对随机截距进行检验, 简单理解为不同观察者Y指标初始值之间的差异具有显著统计学意义。

```{r}
lmerTest::ranova(lme_model)
```
*interpret result: *如果P值小于0.05，可以理解成有必要考虑随机效应。


```{r}
test_performance(lme_model, lme_model2)

compare_performance(lme_model, lme_model2) |> plot()
```

```{r}
check_model(lme_model)
```


*Group-level Effects*

此处的group为患者，注意患者数目对绘图的影响。

```{r}
random <- estimate_grouplevel(lme_model)
random

plot(random) +
  theme_lucid()
```

```{r}
# type III
car::Anova(lme_model, type = 'III')


# Satterthwaite's method
anova(lme_model)


# to see all 134 models
# coef(lme_model)

plot(ggemmeans(lme_model, terms = c("time", "class"))) + 
  ggplot2::ggtitle("GLMER Effect plot")
```

*结果interpre* 在模型构建完成后，应该如何展示分析的结果呢？typeIII结果可以表明变量对模型的贡献度。
同时还可以汇报emmeans，以及不同分组中的emmeans的差值以及对应的95%CI。



*Unit-level predictions*

```{r, include=FALSE}
require(marginaleffects)
```

此图对连续变量更为适用，以下不适用。
```{r}
pred1 <- predictions(lme_model,
                     newdata = datagrid(PatientID = df2$PatientID,
                                        time = c('Day 0','Day 1','Day 7'),
                                        AGE = 30:40,
                                        class = 1
                                        )
                     )

p1 <- ggplot(pred1, aes(AGE, estimate, level = PatientID)) +
      geom_line() +
      labs(y = "Predicted weight", x = "Time", title = "Linear growth model")

p1
```

*Population-level predictions*

To make population-level predictions, we set the PatientID variable to NA, and set re.form=NA. This last argument is offered by the `lme4::predict` function which is used behind the scenes to compute predictions:
```{r}

```




计算emmeans，以及contrasts:
```{r}
# 计算emmeans，以及contrasts
(emm_res <- emmeans(lme_model, specs = c('time', 'class')))

pc <- emmeans::emmeans(lme_model,
                       specs = trt.vs.ctrl ~ time | class,
                       type = "response",
                       ref = 1,
                       adjust = 'fdr', infer = c(TRUE, TRUE))
pc

# 当然还可以 通过如下方式，求得两两比对的结果，结果同pairs(emm_res)
# contrast(emm_res, method='pairwise', by = 'class')
grafify::posthoc_Levelwise(lme_model,
                           c("time", 'class'))
```


```{r}
## Pairwise comparisons, 对于lme模型中emmeans值进行两两比较，自然是针对分类变量
(emm_res <- emmeans(lme_model, specs = 'Time'))
pairs(emm_res)
contrast(emm_res)
plot(emm_res, comparisons = TRUE) + theme_bw() +
  labs(y = "", x = "Estimated marginal mean")
```


```{r}
library(gtsummary)

tbl_data <- df_p_long %>% 
  select(Subject, Folder, !!x_input, ACTARM) %>% 
  distinct() %>% 
  pivot_wider(names_from = Folder, values_from = !!x_input)
  # janitor::clean_names()
  # labelled::remove_labels()


gtsummary::tbl_summary(tbl_data %>% select(-Subject),
                       by = ACTARM,
                       missing = 'no',
                       type = all_continuous() ~ 'continuous2',
                       statistic = list(all_continuous() ~ c("{N_nonmiss}",
                                                             "{mean} ({sd})",
                                                             "{median} ({p25}, {p75})", 
                                                             "{min}, {max}"),
                                        all_categorical() ~ "{n} / {N} ({p}%)")
                       ) %>% 
   modify_header(all_stat_cols() ~ "**{level}**<br>N = {n} ({style_percent(p)}%)") %>%
  add_n() %>% 
  add_p() %>% 
  bold_labels() %>% 
  modify_spanning_header(all_stat_cols() ~ glue::glue("**{x_string}**"))
```


```{r}
gtsummary::tbl_regression(lme_model,
                          intercept = TRUE
                          )
```


*use easystats to get model parameter or effectsize or performance*
下面针对模型的参数和performance进行展示

```{r}
# 首先是是否满足线性混合模型的条件
performance::check_model(lme_model) # 可以看到残差不是很满足正态性分布。

# 其次是模型自身的表现，一般用于模型间的比对
performance::performance(lme_model)

# 相对于summary的结果，多了95%CI,不过通过confint函数也可以计算
parameters::parameters(lme_model)
```


对模型计算effectsize时得到的是Standardization的结果？

```{r}
effectsize::effectsize(lme_model)
```






*use glmer 广义混合模型*

glmer可以用于处理因变量为分类的数据，即是*Multilevel logistic models*，以及种种其他不符合正态分布的因变量数据。

对log转换后的数据进行符合正态分布的线性分析并不是一件值得去做的事情。
The reason we want to use a GLMM for this is that if we imagine a stastical method as E(x), E(ln(x)) is not the same as ln(E(x)). 

```{r}
glme_model <- 
  lme4::glmer(
    score ~ time + class + AGE + (1|`PatientID`),
             data = df2,
             family = 'gaussian'
  )

summary(glme_model) # same as lme_model

# Run logistic model with random intercept and slope
model <- glmer(white ~ homework + (1 + homework | schid), data=mlmdata,
               family=binomial(link="logit"))
summary(model)
```

```{r}

compare_performance(lme_model, glme_model)

plot(compare_performance(lme_model, glme_model))
```



## lme by tidymodels

tidymodels 有提供一系列的统计模型的方法，这是基于R生态的优势之所在。但`tidymodels`一贯的以预测作为模型的主要目的，而在我们的分析中，很多时候模型是作为解释自变量对因变量的影响而展开的。

multilevelmod包支持的模型还是极为广泛的。不过如果只是作为一个模型拟合的过程，似乎没有必要用到tidymodels，毕竟一个模型的拟合所涉及到的各种自变量的问题，是一个需要循环往复的过程，模型的诊断、对比、选择、解释等等才是分析时需要大量考虑的事情。

下面仅在tidymodel的框架下复现一个线性混合模型的应用：

```{r, include=FALSE}

library(tidyverse)
library(tidymodels)
library(multilevelmod)
library(broom.mixed)

tidymodels_prefer()
theme_set(theme_bw())
```


```{r, include=FALSE}
df <- read_csv('~/OneDrive/kintor/Daily_Work/US30001_COVID/lme_data.csv')
```


```{r}
car::qqp(df$LOGCHG, 'norm')

car::qqPlot(df$LOGCHG, 'lnorm')
```


*GEE模型*
```{r}
gee_spec <- 
  linear_reg() %>% 
  set_engine("gee", corstr = "exchangeable")
```


*MME模型*
```{r}
lmer_spec <- 
  linear_reg() %>% 
  set_engine("lmer")

lmer_fit <- 
  lmer_spec %>% 
  fit(LOGCHG ~ VISIT + AGEGR1 + SEX + ACTARM + LOGBASE + (1 | SUBJID), data = df)

lmer_fit
```

`parsnip`类一般包含有模型自身的一些信息
```{r}
lmer_fit %>% extract_fit_engine() %>% 
  summary()
```


*上图的分布提醒我们终然log后的数据，其也呈现出非正态分布的倾向，那么对原始数据AVAL直接进行广义混合模型似乎是一件更为合理的事情 ：*

`MASS::glmmPQL`是对`nlme::lme`的封装，继承`lme`类。

```{r}
car::qqp(df$CHG, 'lnorm')

car::qqp(log10(df$CHG), 'norm')
```


```{r}
PQL_m <- MASS::glmmPQL(fixed = CHG ~ VISIT + AGEGR1 + SEX + ACTARM + LOGBASE,
                       random = ~ 1| SUBJID,
                       family = gaussian(link = "log"),
                       data = df
                       )
```

```{r}
GHQ <- lme4::glmer(LOGCHG ~ VISIT + AGEGR1 + SEX + ACTARM + LOGBASE + (1 | SUBJID), 
             data = df,
             family = gaussian(link = "log"), 
             nAGQ = 1
             )  # Set nAGQ to # of desired iterations, =1就是 Laplace approximation
```


one R structure needs to be specified for each fixed effect and one G structure needs to be specified for each random effect.

```{r}
require(MCMCglmm)
```


```{r}
plot(fitted(lme_model), residuals(lme_model), xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, lty = 2)
lines(smooth.spline(fitted(lme_model), residuals(lme_model)))
```



## MMRM包的使用

最近发现了一个新包`MMRM`，记录下其的应用。

医学研究中的重复测量数据有其对应的考量之处：

```{r}
#   MMRM 
  mod.gls1 <- nlme::gls(Y_comp ~ Group + Time + Group*Time,
                  data = dat,
                  correlation = corSymm(form = ~ 1 | USUBJID),    #  unstructured correlation
                  weights = varIdent(form = ~ 1 | Time),          #  freely estimate variance at subsequent timepoints
                  na.action = na.exclude)


  mod.gls2 <- nlme::gls(Y_mar ~ Group + Time + Group*Time,
                  data = dat,
                  correlation = corSymm(form = ~ 1 | USUBJID),    #  unstructured correlation
                  weights = varIdent(form = ~ 1 | Time),          #  freely estimate variance at subsequent timepoints
                  na.action = na.exclude)

# 倾向于这种用法
mmrm <- gls(y~y0*factor(time)+trt*factor(time),
          na.action=na.omit, 
          data=longData,
          correlation=nlme::corSymm(form=~time | id),
          weights=nlme::varIdent(form=~1|time))
summary(mmrm)
library(multcomp)
confint(glht(mmrm, linfct = matrix(c(0,0,0,0,1,0,0,0,0), nrow=1)))
confint(glht(mmrm, linfct = matrix(c(0,0,0,0,1,0,0,1,0), nrow=1)))
confint(glht(mmrm, linfct = matrix(c(0,0,0,0,1,0,0,0,1), nrow=1)))
  
  
# MMRM - 
  mod.us1 <- glmmTMB::glmmTMB(Y_comp ~ Group + Time + Group*Time + us(Time + 0 | USUBJID), 
                  data=dat, 
                  REML = T,
                  dispformula=~0)
  
  mod.us2 <- glmmTMB::glmmTMB(Y_mar ~ Group + Time + Group*Time + us(Time + 0 | USUBJID),
                  data=dat,
                  REML = T,
                  dispformula=~0)
  
  
  mod.lmer1 <- lme4::lmer(Y_comp ~ Group + Time + Group*Time + ( -1 + Time | USUBJID), 
                    data = dat, 
                    control = lmerControl(check.nobs.vs.nRE = 'ignore')) 
  
  
  mod.lmer2 <- lme4::lmer(Y_mar ~ Group + Time + Group*Time + (0 + Time | USUBJID), 
                    data = dat, 
                    control = lmerControl(check.nobs.vs.nRE = 'ignore')) 
  
  
  #  OLS Regression Model 
  mod.ols1 <- lm(Y_comp ~ Time + Group + Time*Group, 
                 data = dat)

  mod.ols2 <- lm(Y_mar ~ Group + Time + Group*Time, 
                            data = dat)
  
  
  # Compute marginal means
  library(emmeans)
  mod.emms.ols1 <- emmeans(mod.ols1, pairwise ~ Group | Time, adjust = 'none',  mode = 'df.error')
  mod.emms.ols2 <- emmeans(mod.ols2, pairwise ~ Group | Time, adjust = 'none',  mode = 'df.error')

  mod.emms.gls1 <- emmeans(mod.gls1, pairwise ~ Group | Time, adjust = 'none',  mode = 'satterthwaite')
  mod.emms.gls2 <- emmeans(mod.gls2, pairwise ~ Group | Time, adjust = 'none',  mode = 'satterthwaite')

  mod.emms.us1 <- emmeans(mod.us1, pairwise ~ Group | Time, adjust = 'none',  mode = 'df.error')
  mod.emms.us2 <- emmeans(mod.us2, pairwise ~ Group | Time, adjust = 'none',  mode = 'df.error')


  # Kenward Rogers Degrees of Freedom
  mod.emms.lmer1.kr <- emmeans(mod.lmer1, pairwise ~ Group | Time, adjust = 'none', mode = "kenward" )
  mod.emms.lmer2.kr <- emmeans(mod.lmer2, pairwise ~ Group | Time, adjust = 'none', mode = "kenward" )
# Does not align with SAS output
  
  # Satterthwaite Degrees of Freedom:
  mod.emms.lmer1.sat <- emmeans(mod.lmer1, pairwise ~ Group | Time, adjust = 'none', mode = 'satterthwaite' )
  mod.emms.lmer2.sat <- emmeans(mod.lmer2, pairwise ~ Group | Time, adjust = 'none', mode = 'satterthwaite' )
```


```{r}
library(mmrm)

```


以下公式是错误的，其公式的用法和`lme4`不同。正如其文档所说，其不支持个体间随机效应的应用。。
```{r}
# specifying an unstructured covariance matrix. 

# 此公式错误
# mmrm_res <- mmrm(formula = score ~ time + class + AGE + us(1|`PatientID`),
#                  data = df2,
#                  reml = TRUE
#                  )

# 只考虑随机截距的模型
mmrm_res <- mmrm(formula = score ~ time + class + AGE + us(time|`PatientID`),
                 data = df2,
                 reml = TRUE
                 )
```

```{r}
mmrm_res
```

The summary() method then provides the coefficients table with Satterthwaite degrees of freedom as well as the covariance matrix estimate:
```{r}
summary(mmrm_res)
```



*此处有个问题需要重视：*
在以前的分析中，我们知道，time，这一变量是不适合纳入到随机截距里的，

```{r}
# ?mmrm_control
mmrm_res2 <- mmrm(formula = score ~ time * class + AGE + us(time |`PatientID`),
                 data = df2,
                 method = 'Satterthwaite'
                 )
```

```{r}
summary(mmrm_res2)
```

```{r}
emm_res <- emmeans::emmeans(mmrm_res2, ~ class | time)

bb <- contrast(emm_res, method = 'trt.vs.ctrl',
         type = 'response', adjust = 'fdr',
         by = 'time', 
         infer = c(TRUE, TRUE))


plot(bb) +
  theme_bw() +
  geom_vline(xintercept = 0, linetype = 2, color = 'red4')
```

```{r}
emm_res <- emmeans::emmeans(mmrm_res2, ~ class)

bb <- contrast(emm_res, method = 'trt.vs.ctrl',
         type = 'response', adjust = 'fdr',
         # by = 'time', 
         infer = c(TRUE, TRUE))


plot(bb) +
  theme_bw() +
  geom_vline(xintercept = 0, linetype = 2, color = 'red4')
```

















## brms.mmrm

 mixed model for repeated measures (MMRM) run by `brms`.
 `brms` package is a package provides an interface to fit Bayesian generalized (non-)linear multivariate multilevel models using Stan. 
 

```{r}
library(brms)
library(brms.mmrm)
```






