---
title: "feature selection"
format: html
---

# feature selection in R

> https://jtr13.github.io/cc21fall2/feature-selection-in-r.html
> https://cran.r-project.org/web/packages/familiar/vignettes/feature_selection_precompiled.html
> http://r-statistics.co/Variable-Selection-and-Importance-With-R.html


特征选择。


There are several popular feature selection methods in machine learning. Here are some of the most commonly used ones:

Recursive Feature Elimination (RFE): This method recursively removes features from the dataset and evaluates the performance of the model at each step. It selects the subset of features that results in the best model performance.

Principal Component Analysis (PCA): PCA is a technique that transforms the original features into a new set of uncorrelated features (principal components) that explain the maximum amount of variance in the data. The principal components can be used as features for the model.

Lasso regularization: Lasso is a regularization technique that adds a penalty term to the objective function of the model. The penalty term encourages the model to select a sparse set of features by shrinking the coefficients of less important features to zero.

Mutual Information: This method measures the mutual information between each feature and the target variable. It selects the subset of features with the highest mutual information.

Tree-based feature selection: This method uses decision trees to evaluate the importance of each feature. It selects the subset of features with the highest importance scores.

Correlation-based feature selection: This method evaluates the correlation between each feature and the target variable. It selects the subset of features with the highest correlation.

Genetic algorithms:

`caret::safs` 模拟退火算法: 

Boruta和Vita算法，不去除冗余变量，对于不同的数据集包含的变量可能相差较大的生物医药数据比较合适。类似的方法还有Altmann、Permr、2VIM等。

Boruta:
1.初次建模时，把原始变量拷贝一份作为影子变量。
2.原始变量的值随机化后作为对应影子变量的值 (随机化就是打乱原始变量值的顺序)。
3.使用随机森林建模并计算每个变量的重要性得分。
4.对于每一个真实特征变量，统计检验其与所有影子变量的重要性最大值的差别。重要性显著高于影子变量的真实特征变量定义为重要。重要性显著低于影子变量的真实特征变量定义为不重要。
5.所有不重要的变量和影子变量移除。
6.基于新变量构成的数据集再次重复刚才的建模和选择过程，直到所有变量都被分类为重要或不重要，或达到预先设置的迭代次数。


# Feature Selection packages in R

Feature selection or variable selection in machine learning is the process of selecting a subset of relevant features (variables or predictors) for use in model construction.

Introduction to feature selection: https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/

## Packages

### FSinR

Examples: <br>
https://cran.r-project.org/web/packages/FSinR/vignettes/FSinR.html <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/FSinR/FSinR.pdf

### Boruta

Examples: <br>
https://www.analyticsvidhya.com/blog/2016/03/select-important-variables-boruta-package/ <br>
https://www.datacamp.com/community/tutorials/feature-selection-R-boruta <br>
https://www.listendata.com/2017/05/feature-selection-boruta-package.html <br>
http://www.cybaea.net/Journal/2010/11/15/Feature-selection-All-relevant-selection-with-the-Boruta-package/ <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/Boruta/Boruta.pdf

### caret

Examples: <br>
http://ml-tutorials.kyrcha.info/rfe.html <br>
http://www.cybaea.net/Journal/2010/11/16/Feature-selection-Using-the-caret-package/ <br>
https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/ <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/caret/caret.pdf

### spFSR

Examples: <br>
https://cran.r-project.org/web/packages/spFSR/vignettes/spFSR.html <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/spFSR/spFSR.pdf

### varSelRF

Examples: <br>
https://www.kaggle.com/netzone/mushroom-classification-using-varselrf <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/varSelRF/varSelRF.pdf

### CORElearn

Examples: <br>
https://ucilnica.fri.uni-lj.si/pluginfile.php/24621/mod_resource/content/3/lab%205%20-%20attribute%20evaluation.R <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/CORElearn/CORElearn.pdf

### FSelector

Examples: <br>
https://miningthedetails.com/blog/r/fselector/  <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/FSelector/FSelector.pdf

### EFS

Examples: <br>
https://biodatamining.biomedcentral.com/articles/10.1186/s13040-017-0142-8  <br>
CRAN pdf: <br>
https://cran.r-project.org/web/packages/EFS/EFS.pdf

### RWeka

CRAN pdf: <br>
https://cran.r-project.org/web/packages/RWeka/RWeka.pdf

### featurefinder

CRAN pdf: <br>
https://cran.r-project.org/web/packages/featurefinder/featurefinder.pdf

### more...

mRMRe: A package that implements the minimum redundancy maximum relevance algorithm, a feature selection method that selects features that are both relevant to the target variable and not redundant with each other.

Rborist: A package that implements the Borist algorithm, a feature selection method that evaluates the importance of features by comparing them with a random forest model.

CORElearn: A package that includes several feature selection methods, such as ReliefF and Correlation-based Feature Selection.

caretEnsemble: A package that includes several ensemble feature selection methods, such as recursive feature elimination and forward selection.



# 一些示例

> https://bookdown.org/max/FES/recursive-feature-elimination.html


此处主要记录特征递归消除(RFE, recursive feature elimination)的应用，它基于模型预测性能评估指标如准确性、mse等选 择一个性能较佳的最小集合的特征变量。它首先应用所有的特征变量构建模型，然后移除对模型最不重要的一定比例的变量再次构建模型；持续迭代直至获得准确性最高的模型。在后续应用预测模型时，只需要使用数目比较少的变量，这样的好处是便于新样品的变量检测。


```{r}
library(caret)
```


```{r}
# ?caret::rfe
# x: 训练集数值矩阵 (不包含响应值或分类信息)
# y: 响应值或分类信息向量
# sizes: 一个整数向量，设定需要评估的变量子集的大小。默认是2^(2:4)，这个怎么确定呢
# metric: By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" and "Kappa" for classification.
# rfeControl: 模型评估所用的方法、性能指标和排序方式等。

# rfFuncs
control <- rfeControl(functions=rfFuncs, method="repeatedcv", number=10, repeats=5)

rfe <- caret::rfe(x=train_data, y=train_data_group, size=subsets, rfeControl=control)
```


```{r}
print(rfe, top=10)
```

```{r}
plot(rfe, type=c("g", "o"))
```

可以使用predictors函数提取最终选定的最小关键特征变量集，也可以直接从rfe对象中提取。
```{r}
predictors(rfe)
```






















