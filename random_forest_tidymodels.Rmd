---
title: "random_forest_tidymodels"
author: "liuc"
date: '2022-05-23'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## random_forest_tidymodels

Random forest model by tidymodels

```{r echo=FALSE}
library(tidyverse)
library(tidymodels)
library(vip)

tidymodels_prefer()
doParallel::registerDoParallel()
```


*prepare input data*:
以下链接有多了癌症组织表达数据集：https://file.biolab.si/biolab/supp/bi-cancer/projections/
可以拿来做测试数据。
The prostate data set (Singh et al.) includes the gene expression measurements for 52 prostate tumors and 50 adjacent normal prostate tissue samples.

```{r}
expr_file <- "datasets/prostat.expr.symbol.txt"
metadata_file <- "datasets/prostat.metadata.txt"

expr_mat <- read_delim(expr_file, delim = '\t') %>% 
  janitor::clean_names()
metadata <- read_delim(metadata_file, delim = '\t') %>% 
  janitor::clean_names()

# 此处或可以加上`Boruta`的结果进行一些变量筛选工作
input_data <- expr_mat %>% column_to_rownames('symbol') %>% t() %>% 
  as.data.frame() %>% rownames_to_column() %>% as_tibble() %>% 
  janitor::clean_names() %>% 
  left_join(metadata, by = c('rowname'='sample')) %>% 
  mutate(class = if_else(class=='tumor', 1, 0)) %>% 
  mutate(class = as_factor(class))


# 此处也可以保留rowname列，在下文中通过recipe中的`update_role`进行
set.seed(42)
df_split <- initial_split(input_data %>% select(-rowname))

df_train <- training(df_split)
df_test <- testing(df_split)

```


#### rpart 分类问题
树模型的种类繁多，此处选择`rpart`包。

```{r}
class_tree_spec <- decision_tree() %>%
  set_engine('rpart') %>% 
  set_mode("classification")

# 初步的模型, 进行模型的一些探索性分析
class_tree_fit <- class_tree_spec %>% 
  fit(class ~ ., data = df_train)


augment(class_tree_fit, new_data = df_train) %>%
  accuracy(truth = High, estimate = .pred_class)

augment(class_tree_fit, new_data = df_train) %>%
  conf_mat(truth = High, estimate = .pred_class)
```


`rpart.plot` 可以对rpart数进行可视化，此处做一个展示:
```{r}
class_tree_fit %>% 
  extract_fit_engine() %>% 
  rpart.plot::rpart.plot()

```


交叉验证和网格搜索确定最后的模型
```{r}
class_tree_wf <- workflow() %>%
  add_model(class_tree_spec %>% 
              set_args(cost_complexity = tune())) %>% # 选择网格搜索的参数
  add_formula(class ~ .)
# k-fold cross-validation
set.seed(42)
df_fold <- vfold_cv(df_train)

param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)

# 运行时间也太长了。。
tune_res <- tune_grid(
  class_tree_wf, 
  resamples = df_fold, 
  grid = param_grid, 
  metrics = metric_set(accuracy)
)
autoplot(tune_res)

best_complexity <- select_best(tune_res)

class_tree_final <- finalize_workflow(class_tree_wf, best_complexity)

class_tree_final_fit <- fit(class_tree_final, data = df_train)
class_tree_final_fit

```



```{r}
class_tree_final_fit %>%
  extract_fit_engine() %>%
  rpart.plot()
```



#### Random Forests 分类问题

随机森林的R包中常用的有`ranger`, `randomForest`包，在此选择用ranger包，其的速度似乎更快。

```{r}
rf_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %>%
  set_engine("ranger") %>%
  set_mode("classification")

# tune the hyperparameters
class_rf_wf <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_formula(class ~.)


set.seed(42)
trees_folds <- vfold_cv(df_train,
                        v = 10
                        )

tune_res <- tune_grid(
  class_rf_wf,
  resamples = trees_folds,
  grid = 20
)

# save(tune_res, file = './datasets/tune_res_rf.rda')
```


AUC for `tune_res`: 
在进行超参数网格搜索时可以先设置一些值进行，然后根据模型的表现多尝试几次tune, 再最终选择合适的超参数。
以下探索在各个参数的情况下，以roc_auc matrics为标准的一些参数变化，为了演示grid设置较少。
```{r}
# load('./datasets/tune_res_rf.rda')

tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")

```


*Choosing the best model*
```{r}
best_auc <- select_best(tune_res, "roc_auc")

final_rf <- finalize_model(
  rf_spec,
  best_auc
)

final_rf


# final_wf <- class_rf_wf %>% finalize_workflow(final_rf)
final_wf <- workflow() %>% add_model(final_rf) %>% 
  add_formula(class ~ .)
final_fit <- final_wf %>% fit(df_train)

# This function fits a final model on the entire training set and evaluates on the testing set
final_res <- final_wf %>%
  last_fit(split = df_split)
final_res %>% 
  collect_metrics()
```


variable importance by package `vip`：
变量重要性也是经常的目标。
```{r}
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(class ~ .,
    data = df_train
  ) %>%
  vip::vip(geom = "point")
```


```{r}
cancer_pred <- predict(final_fit, new_data = df_test) %>%
  bind_cols(predict(final_fit, df_test, type = "prob")) %>%
  bind_cols(df_test %>% select(class))

cancer_pred %>%  roc_auc(truth = class, .pred_tumor, event_level="second")

cancer_pred %>% accuracy(truth = class, .pred_class)

# confusion matrix
final_res %>%
    collect_predictions() %>%
    conf_mat(class, .pred_class)
```


绘制ROC曲线
```{r}
collect_predictions(final_res) %>%
  roc_curve(class, .pred_normal) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  ) +
  coord_equal()
```


save model
```{r}
crash_wf_model <- final_res$.workflow[[1]]
predict(crash_wf_model, df_test[10, ])


saveRDS(crash_wf_model, here::here("crash-api", "crash-wf-model.rds"))

collect_metrics(crash_res) %>%
  write_csv(here::here("crash-api", "crash-model-metrics.csv"))
```


```{r}
tidypredict::tidypredict_fit(final_rf)[[1]]
```





