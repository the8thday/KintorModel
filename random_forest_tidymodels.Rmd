---
title: "random_forest_tidymodels"
author: "liuc"
date: '2022-05-23'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## random forest by tidymodels

> http://www.ehbio.com/ML/randomForest.html
> https://towardsdatascience.com/understanding-random-forest-58381e0602d2


随机森林，采用随机抽样的ensembled决策树构建的模型。其属于集成学习中的bagging(Bootstrap AGgregation 的简称).
A `bagging model` is the same as a random forest where mtry is equal to the number of predictors.

随机森林是，集成学习方法的一种，首先其将数据随机重采样，在生成多个数据样本后，对这些数据进行决策树建模，同时子集数据集的特征也具有随机性，这是随机森林和决策树之间的关键区别。对于回归问题，所有树的输出值是取的平均值；对于分类问题，投票次数最多的类别（即最常见的类别变量）将确定为最终类别。在该训练样本中，有三分之一被留作测试数据，称为袋外 (oob) 样本，将 oob 样本用于交叉验证，最终确定预测结果。
大概的过程如下：对于一个`n x p`的矩阵，首先从数据集中有放回的随机选取n个样本为一数据集，训练一颗决策树，每棵决策树随机选择m个(m<<p)特征进行每个决策变量的选择，决策树野蛮生长、不剪枝，重复此过程至t颗决策树，最后聚合t颗数的结果做出最后的决策。

*oob* error rate，随机森林中每一颗决策树在构建时因为有放回的采样缘故，约有1/3的样本不会被用到，这些没有被用到的样本会用来测试该决策树的分类能力。随机森林与其他机器学习方法不同的是存在OOB，相当于自带多套训练集和测试集，自己内部就可以通过OOB值评估模型的准确度 (Bootstrap方式)。其他一些机器学习方法却没有这一优势。


*常适用的数据*，随机森林对于维度很高的数据（特征很多的数据）比如微生物组数据，不用特征工程也可以直接使用。对于连续数据和分类数据混合的数据集，


*重要的超参数*，随机森林算法有三个主要的超参数，需要在训练之前进行设置。 其中包括节点大小(min_n)、树的数量(ntree)和 采样的特征数量(mtry)。
其中采样的特征数量通常randomForest() `p / 3` variables when building a random forest of regression trees, and `sqrt(p)` variables when building a random forest of classification trees. 
树的数量一般会控制在500以下，but one should never use over 500 trees because it is a waste of time.虽然有人这么说， 但还是会用到很多的trees的。
当然具体还要依据数据的情况而定，`dials`包所提供的一些列的函数值得参考。

其他的可以tune的超参数，Criterion(gini or mse, et.), 


*随机森林对于特征重要性的评估*，基尼重要性和平均不纯度减少 (MDI) 常用于衡量排除给定变量时模型准确度的降低程度。 此外，排列重要性（又称 MDA，平均精度下降）也是一种衡量重要性的方法。 MDA 通过随机排列 oob 样本中的特征值来识别准确性的平均降低程度。 


*优缺点：*

1. 它可以出来很高维度（特征很多）的数据，并且不用降维，无需做特征选择
2. 它可以判断特征的重要程度
3. 可以判断出不同特征之间的相互影响
4. 不容易过拟合
5. 训练速度比较快，容易做成并行方法
6. 实现起来比较简单
7. 对于不平衡的数据集来说，它可以平衡误差。
8. 如果有很大一部分的特征遗失，仍可以维持准确度。

缺点

1. 随机森林已经被证明在某些噪音较大的分类或回归问题上会过拟合。
2. 对于有不同取值的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的


```{r, include=FALSE}

library(tidyverse)
library(tidymodels)
library(vip)
library(usemodels)


tidymodels_prefer()

# for clustrer
cl <- parallel::makePSOCKcluster(4)
doParallel::registerDoParallel(cl)
```


*prepare input data*:

以下链接有多了癌症组织表达数据集：https://file.biolab.si/biolab/supp/bi-cancer/projections/
可以拿来做测试数据。

The prostate data set (Singh et al.) includes the gene expression measurements for 52 prostate tumors and 50 adjacent normal prostate tissue samples.
本测试数据虽则样本数量不是很多，但是变量挺多，采用决策树模型并非是一个好的策略。

```{r, include=FALSE}

expr_file <- "datasets/prostat.expr.symbol.txt"
metadata_file <- "datasets/prostat.metadata.txt"

expr_mat <- read_delim(expr_file, delim = "\t") %>%
  janitor::clean_names()
metadata <- read_delim(metadata_file, delim = "\t") %>%
  janitor::clean_names()

# 此处或可以加上`Boruta`的结果进行一些变量筛选工作
input_data <- expr_mat %>%
  column_to_rownames("symbol") %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  as_tibble() %>%
  janitor::clean_names() %>%
  left_join(metadata, by = c("rowname" = "sample")) %>%
  mutate(class = if_else(class == "tumor", 1, 0)) %>%
  mutate(class = as_factor(class))


# 此处也可以保留rowname列，在下文中通过recipe中的`update_role`进行
set.seed(42)
df_split <- initial_split(input_data %>% select(-rowname))

df_train <- training(df_split)
df_test <- testing(df_split)

```

##### 一个网上的RF小例子

```{r}
# 一个网上的小例子
# https://juliasilge.com/blog/ikea-prices/

ikea <- read_csv("~/Downloads/ikea.csv")

ikea_df <- ikea %>%
  select(price, name, category, depth, height, width) %>%
  mutate(price = log10(price)) %>%
  mutate_if(is.character, factor)

ikea_df

```

```{r}
set.seed(123)
df_split <- initial_split(ikea_df, strata = price)
df_train <- training(df_split)
df_test <- testing(df_split)

set.seed(234)
dials_grid <- bootstraps(df_train, strata = price, times = 10)


dials_grid
```

```{r}
library(textrecipes)
ranger_recipe <-
  recipe(formula = price ~ ., data = df_train) %>%
  step_other(name, category, threshold = 0.01) %>%
  step_clean_levels(name, category) %>%
  step_impute_knn(depth, height, width)

ranger_spec <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
  set_mode("regression") %>%
  set_engine("ranger")

ranger_workflow <-
  workflow() %>%
  add_recipe(ranger_recipe) %>%
  add_model(ranger_spec)

```

```{r}
set.seed(8577)
# doParallel::registerDoParallel()

ranger_tune <-
  tune_grid(ranger_workflow,
    resamples = dials_grid,
    grid = 11
  )
```


```{r}
show_best(ranger_tune, metric = "rmse")
```
```{r}
final_rf <- ranger_workflow %>%
  finalize_workflow(select_best(ranger_tune, metric = 'rmse'))

final_rf
```

```{r}
final_fit <- last_fit(final_rf, df_split)

final_fit
```

```{r}
attributes(final_fit)
```




#### tidymodels做决策树分类问题

首先构建一个决策树模型，以帮助确定超参数的取值。
本基因表达数据集outcome为二分类结果。两种结局结果较为均衡，一个50例一个52例。

决策树模型的种类繁多，此处选择`rpart`包。

```{r}
class_tree_spec <- decision_tree() %>%
  set_engine('rpart') %>% 
  set_mode("classification")

# 初步模型, 进行模型的一些探索性分析，为最终模型确定一些参数
class_tree_fit <- class_tree_spec %>% 
  fit(class ~ ., data = df_train)


# 在训练集数据上的一些模型指标
augment(class_tree_fit, new_data = df_train) %>%
  accuracy(truth = class, estimate = .pred_class)

augment(class_tree_fit, new_data = df_train) %>%
  conf_mat(truth = class, estimate = .pred_class)
```


`rpart.plot` 可以对rpart数进行可视化，此处做一个展示:

```{r}
class_tree_fit %>% 
  extract_fit_engine() %>% 
  rpart.plot::rpart.plot()

```


交叉验证和网格搜索确定最后的模型,
决策树模型需要确认nsplit等参数，一般会通过CP值分析得到，不过在网格搜索中得到的nsplit值。

在决策树模型中，超参数常见的设置为`cost_complexity` 和 `tree_depth`.

```{r}
class_tree_wf <- workflow() %>%
  add_model(class_tree_spec %>% 
              set_args(cost_complexity = tune(),
                       tree_depth = tune()
                       )) %>% # 选择网格搜索的参数
  add_formula(class ~ .)

# k-fold cross-validation
set.seed(42)
df_fold <- vfold_cv(df_train)


# 利用dials包，进行超参数的设定
param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), 
                           tree_depth(),
                           levels = 10)

dials_para <- dials::grid_random(cost_complexity(),
                                 tree_depth(),
                                 size = 5
                                 )

# 运行时间也太长了。。
tune_res <- tune_grid(
  class_tree_wf, 
  resamples = df_fold, 
  grid = dials_para, 
  metrics = metric_set(accuracy)
)

autoplot(tune_res)

```


简单看下两个超参数在两个不同matrices的表现：
```{r}
tree_res %>% 
  collect_metrics()

tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(linewidth = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```


```{r}

best_complexity <- select_best(tune_res)

class_tree_final <- finalize_workflow(class_tree_wf, best_complexity)

class_tree_final_fit <- fit(class_tree_final, data = df_train)
class_tree_final_fit
```


```{r}
class_tree_final_fit %>%
  extract_fit_engine() %>%
  rpart.plot()
```
在调整完参数之后，图咋没啥改变呢。。


```{r}
class_tree_final_fit %>%
  collect_predictions() %>% 
  roc_curve(class, .pred_PS) %>% 
  autoplot()
```



We can use the function last_fit() with our finalized model; this function fits the finalized model on the full training data set and evaluates the finalized model on the testing data.
```{r}
final_fit <- 
  final_wf %>%
  last_fit(df_split) 

final_fit %>%
  collect_metrics()
```

```{r}
final_tree <- extract_workflow(final_fit)

# 应该和class_tree_final_fit是一样的，不过跑的太慢了，没有测试
final_tree

final_tree %>% 
  extract_fit_parsnip() %>% 
  vip::vip()
```



#### Random Forests 分类问题

随机森林的R包中常用的有`ranger`, `randomForest`包，在此选择用ranger包，其的速度似乎更快。
Whereas the `randomForest` package provides forests based on traditional decision trees, the `cforest()` function in the `party` package can be used to generate random forests based on conditional inference trees. If predictor variables are highly correlated, a random forest using conditional inference trees may provide better predictions.

不同于决策树、罗辑回归等模型，随机森林等一众模型，其在变量解释上有黑盒子模型之称。虽则随机森林也有提供变量重要性等指标，在构建完随机森林后，我们将采用XAI计划中的一些包进行模型解释上的一些示例。

```{r}
show_engines('rand_forest')


rf_spec <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", 
             impotance = 'impurity', 
             # num.threads = 4
             ) %>%
  set_mode("classification")


# 对于变量多达9000个，而样本数量只有100多个的样本，是否需要一些recipe的过程呢
# 随机森林似乎不需要

class_rf_wf <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_formula(class ~.)

```


`mtry`参数的设置？the number of predictors that are sampled at splits in a tree-based model.

By default, randomForest() p / 3 variables when building a random forest of regression trees, and sqrt(p) variables when building a random forest of classification trees. 

```{r}
# 查看parsnip对象的所有参数
args(rand_forest)

extract_parameter_set_dials(class_rf_wf)
```


```{r}
# tune the hyperparameters
set.seed(42)

trees_folds <- vfold_cv(df_train,
                        v = 10
                        )

# 在进行具体的模型构建过程中，超参数的范围选择是件需要参考的事情
# dials 可以提供一些参考，是一个不错的设计
# 比如在本示例种，数据集大小为76x9022，问题为分类，则约95个mtry
grid <- expand.grid(
      mtry = c(50, 100, 200), 
      min_n = c(),
      trees = c(100, 300, 500)
    )

# use dials to create grid
dials_grid <- dials::grid_random(
  finalize(mtry(), x = df_train),
  min_n(),
  trees(),
  size = 10
)


# 网格搜索后的对象为
tune_res <- tune_grid(
  class_rf_wf,
  resamples = trees_folds,
  control = control_grid(save_pred = TRUE),
  grid = dials_grid
)

# save(tune_res, file = './datasets/tune_res_rf.rda')
```


在进行超参数网格搜索时可以先设置一些值进行，然后根据模型的表现多尝试几次tune, 再最终选择合适的超参数。
以下探索在各个参数的情况下，以`roc_auc` matrics为标准的一些参数变化，为了演示grid设置较少。
利用验证集数据进行自动的`hyperparameter`设置也是不错的选择。

```{r}
# load('./datasets/tune_res_rf.rda')


tune_res %>%
  collect_metrics()

show_best(tune_res, metric = "roc_auc")

tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")

```
*interpret the result: *


```{r}
autoplot(tune_res)

```



*Choosing the best model*

得到超参数后，对候选的模型进行拟合，注意目前得到的参数只是超参数，而机器学习里的参数是模型拟合的过程。

```{r, eval=FALSE}
# 本cell可以不运行
best_auc <- select_best(tune_res, "roc_auc")

final_rf <- finalize_model(
  rf_spec,
  best_auc
)

final_rf


# final_wf <- class_rf_wf %>% finalize_workflow(final_rf)
final_wf <- workflow() %>% add_model(final_rf) %>% 
  add_formula(class ~ .)

final_fit <- final_wf %>% fit(df_train)


```

```{r}
rf_auc <- 
  tune_res %>% 
  collect_predictions(parameters = best_auc) %>% 
  roc_curve(., truth = class, .pred_0) %>% 
  mutate(model = "Random Forest")

rf_auc %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(linewidth = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_viridis_d(option = "plasma", end = .6) +
  theme_bw()
```


`final_res`便是在测试集数据上拟合过的模型，其应该包含最终模型吧
和`final_fit`二者运行其一即可。

```{r}
best_auc <- select_best(tune_res, "roc_auc")

final_rf <- finalize_model(
  rf_spec,
  best_auc
) %>% 
  set_engine("ranger", 
             impotance = 'impurity' # 'permutation'
             )

final_wf <- class_rf_wf %>% 
  update_model(final_rf)


# This function fits a final model on the entire training set and evaluates on the testing set
final_res <- final_wf %>%
  last_fit(split = df_split)

final_res %>% 
  collect_metrics()
```

测试集数据

```{r}
test_aug <- augment(final_fit, new_data = df_test) %>% 
  select(class, starts_with('.'))
```



variable importance by package `vip`：
变量重要性也是经常需要去关注的指标。在随机森林模型中用以解释变量的重要性、贡献度。

`vip` functions when we want to use model-based methods that take advantage of model structure (and are often faster);
DALEX functions when we want to use model-agnostic methods that can be applied to any model

```{r}
# 此处之所以在重新跑一遍是为了演示，在模型构建中可以设置参数的
vip_res <- final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(class ~ .,
    data = df_train
  ) 

vip_res %>%
  vip::vip(geom = "col", num_features = 20)


# final_res %>% 
#   extract_fit_parsnip() %>% 
#   vip::vip(num_features = 20)
```

在测试集数据上对模型参数，

```{r}
cancer_pred <- predict(final_fit, new_data = df_test) %>%
  bind_cols(predict(final_fit, df_test, type = "prob")) %>%
  bind_cols(df_test %>% select(class))

# 和上面 final_res的结果一致
cancer_pred %>%  roc_auc(truth = class, .pred_1, event_level="second")

cancer_pred %>% accuracy(truth = class, .pred_class)

# confusion matrix for test dataset
final_res %>%
    collect_predictions() %>%
    conf_mat(class, .pred_class)
```


在测试集数据上绘制ROC曲线:

```{r}
collect_predictions(final_res) %>%
  roc_curve(class, .pred_0) %>%
  autoplot()
```
这曲线也太丑了，得优化一下呀。



*save model*

```{r}
# crash_wf_model 为最终的模型，不过奇怪的是和final_fit有些地方不一致？
crash_wf_model <- final_res$.workflow[[1]]
predict(crash_wf_model, df_test[10, ])


saveRDS(crash_wf_model, here::here("crash-api", "crash-wf-model.rds"))

collect_metrics(crash_res) %>%
  write_csv(here::here("crash-api", "crash-model-metrics.csv"))
```








